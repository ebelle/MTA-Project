{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function creates a list of all possible subway strings for each of the subway lines.\n",
    "For example, for the ace line, this returns a,c,e,ac,ae,ce,&ace\"\"\"\n",
    "import itertools\n",
    "def generate_subway_strings():\n",
    "    is_subway = []\n",
    "    subway_list = [\"ace\",\"bdfm\",\"jz\",\"nrqw\",\"l\",\"s\",\"g\",\"fg\",\"em\",\"jmz\",\"ef\",\"mr\",\"bc\",\n",
    "                   \"123\",\"456\",\"7\",\"25\", \"34\"]\n",
    "    for subway in subway_list:\n",
    "        #the longest string in subway list is 4 characters\n",
    "        for i in range(1,5):\n",
    "            for j in itertools.combinations(subway, i):\n",
    "                subway_combination = ''.join(j)\n",
    "                if subway_combination not in is_subway:\n",
    "                    is_subway.append(subway_combination)\n",
    "    return is_subway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/emilycampbell/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('universal_tagset')\n",
    "import csv\n",
    "\n",
    "class TokensAndTags:\n",
    "    \n",
    "    def __init__(self, csv_file):\n",
    "        \"\"\"Requires one arguement, a csv file\"\"\"\n",
    "        self.csv_file = csv_file\n",
    "    \n",
    "    def text_from_csv(self):\n",
    "        \"\"\"Reads the csv file and yields tweets. Assumes 3 columns. Strips apostrophes and slashes\"\"\"\n",
    "        with open (self.csv_file, \"r\") as source:\n",
    "            csv_reader = csv.reader(source)\n",
    "            for _,_,text in csv_reader:\n",
    "                text = text.replace(\"â€™\",\"\").replace(\"'\",\"\").replace(\"/\",\"\")\n",
    "                yield text\n",
    "    \n",
    "    def sentence_boundry(self):\n",
    "        \"\"\"Uses nltk sentence tokenizer to return a list of sentences\"\"\"\n",
    "        list_sentences = []\n",
    "        s = \"\".join(self.text_from_csv())\n",
    "        sentences = nltk.sent_tokenize(s)\n",
    "        for sentence in sentences:\n",
    "            if sentence in list_sentences:\n",
    "                pass\n",
    "            else:\n",
    "                list_sentences.append(sentence)\n",
    "        return list_sentences\n",
    "    \n",
    "    def make_tokens(self):\n",
    "        \"\"\"Returns a list of sentences, each of which is a list of tokens. Uses TweetTokenizer\"\"\"\n",
    "        tokens = [] \n",
    "        for sentence in self.sentence_boundry():\n",
    "            tokenized = nltk.tokenize.TweetTokenizer().tokenize(sentence)\n",
    "            for token in tokenized:\n",
    "                tokens.append(token)\n",
    "        return tokens\n",
    "    \n",
    "    def get_tokens_tags(self):\n",
    "        tokens = self.make_tokens()\n",
    "        final_tokens = []\n",
    "        final_tags = []\n",
    "        for token, tag in nltk.pos_tag(tokens, tagset = 'universal'):\n",
    "            final_tokens.append(token.casefold())\n",
    "            final_tags.append(tag)\n",
    "        return final_tokens,final_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mta_text = TokensAndTags(\"mta_subway_tweets.csv\")\n",
    "tokens,tags = mta_text.get_tokens_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "class Find_Trains:\n",
    "    \n",
    "    def __init__(self,tokens,tags):\n",
    "        \"\"\"The class takes two arguments, a list of tags and a list of tokens\"\"\"\n",
    "        self.tokens = tokens\n",
    "        self.tags = tags\n",
    "        \"\"\"This is a complete list of all the possible train combinations\"\"\"\n",
    "        self.is_train = self.is_train = ['a', 'c', 'e', 'ac', 'ae', 'ce', 'ace', \n",
    "                         'b', 'd', 'f', 'm', 'bd', 'bf', 'bm', 'df', 'dm', 'fm', 'bdf', 'bdm', 'bfm', 'dfm', 'bdfm', \n",
    "                         'j', 'z', 'jz', \n",
    "                         'n', 'r', 'q', 'w', 'nr', 'nq', 'nw', 'rq', 'rw', 'qw', 'nrq', 'nrw', 'nqw', 'rqw', 'nrqw', \n",
    "                         'l', 's', 'g', \n",
    "                         'fg', 'em', 'jm', 'mz', 'jmz', 'ef', 'mr', 'bc',\n",
    "                         '1', '2', '3', '12', '13', '23', '123', \n",
    "                         '4', '5', '6', '45', '46', '56', '456', \n",
    "                         '7', \n",
    "                         '25', '34']\n",
    "        \"\"\"This is only letter trains, excepting the A/a train which is dealt with below\"\"\"\n",
    "        self.is_letter_train = frozenset(['c', 'e', 'ac', 'ae', 'ce', 'ace', \n",
    "                         'b', 'd', 'f', 'm', 'bd', 'bf', 'bm', 'df', 'dm', 'fm', 'bdf', 'bdm', 'bfm', 'dfm', 'bdfm', \n",
    "                         'j', 'z', 'jz', \n",
    "                         'n', 'r', 'q', 'w', 'nr', 'nq', 'nw', 'rq', 'rw', 'qw', 'nrq', 'nrw', 'nqw', 'rqw', 'nrqw', \n",
    "                         'l', 's', 'g', \n",
    "                         'fg', 'em', 'jm', 'mz', 'jmz', 'ef', 'mr', 'bc',])\n",
    "        \"\"\"This is only number trains\"\"\"\n",
    "        self.is_number_train = frozenset(['1', '2', '3', '12', '13', '23', '123', \n",
    "                         '4', '5', '6', '45', '46', '56', '456', \n",
    "                         '7', \n",
    "                         '25', '34'])\n",
    "        \"\"\"This is only the A/a train\"\"\"\n",
    "        self.is_a_train = frozenset(['a'])\n",
    "        \"\"\"This is a list of common train nouns that are used after train characters\"\"\"\n",
    "        self.train_noun_list = [\"train\", \"trains\", \"subway\",\"line\",\"lines\", \"stop\", \"station\", \n",
    "                           \"service\", \"platform\", \"track\"]\n",
    "        \"\"\"This is a list of common train adjectives that are used before and after train characters\"\"\"\n",
    "        self.train_adj_list = frozenset([\"express\", \"exp\",\"local\",\"uptown\", \"downtown\", \"queensbound\", \n",
    "                          \"queens-bound\" \"southbound\", \"northbound\", \"southbound\", \"bound\", \n",
    "                          \"manhattan-bound\",\"brooklyn-bound\", \"bronx-bound\", \"island-bound\",\n",
    "                          \"astoria-bound\",\"sb\",\"nb\"])\n",
    "        \"\"\"This is a list of common time words to filter out number trains from times\"\"\"\n",
    "        self.times = frozenset([\"seconds\",\"minute\",\"minutes\",\"min\",\"mins\",\"hour\",\"hours\",\"hr\",\"hrs\",\n",
    "                               \"day\",\"days\",\"week\",\"weeks\",\"month\",\"months\",\"year\",\"years\",\"yrs\"])\n",
    "        \n",
    "    \n",
    "    def find_a_trains(self):\n",
    "        \"\"\"This function finds A/a trains and excludes instances of the indefinite article 'a'\n",
    "        The following criteria are used (in order): 1) if the letter A comes after an adjective or determiner\n",
    "        except 'such' 2) if the letter A comes after another train letter, which is followed by \n",
    "        punctuation or a conjuction 3) if the token before the letter A is included in the train\n",
    "        adjective list 4) if the token after the letter A is included in the train adjective list \n",
    "        and is not followed by another train word or character\"\"\"\n",
    "        trains = []\n",
    "        tokens = self.tokens\n",
    "        tags = self.tags\n",
    "        \"\"\"train_words is list which combines all the train characters and all the train nouns\"\"\"\n",
    "        train_words = self.is_train + self.train_noun_list\n",
    "        for i,token in enumerate(tokens):\n",
    "            if token in self.is_a_train: \n",
    "                if i or i<len(tokens)-1:\n",
    "                    if tags[i-1] in ['ADJ','DET'] and tokens[i-1] not in [\"such\", \"a\"]:\n",
    "                        trains.append(token)\n",
    "                    elif tags[i+1] in [\"CONJ\", \".\"] and tokens[i+2] in self.is_letter_train:\n",
    "                        trains.append(token) \n",
    "                    elif tokens[i-1] in self.train_adj_list:\n",
    "                        trains.append(token)\n",
    "                    elif tokens[i+1] in self.train_adj_list and tokens[i+2] not in train_words:\n",
    "                        trains.append(token)\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "        return trains\n",
    "    \n",
    "    def find_number_trains(self):\n",
    "        \"\"\"This function finds number trains and excludes instances of integers.\n",
    "        The following criteria are used (in order): 1) if the comes before a verb 2) if the number\n",
    "        after an adjective 3) if the number comes after a train adjective 4) if the number comes\n",
    "        before a train adjective 5) if the number comes before a train noun 6) if there is another \n",
    "        train character followed by punctuation or a conjuction before the letter 7) if there is\n",
    "        punctuation or a conjuction followed by another train character after the letter\"\"\"\n",
    "        trains = []\n",
    "        tokens = self.tokens\n",
    "        tags = self.tags\n",
    "        for i,token in enumerate(tokens):\n",
    "            if token in self.is_number_train:\n",
    "                if i or i<len(tokens)-1:\n",
    "                    if tags[i+1] == \"VERB\":\n",
    "                        trains.append(token)       \n",
    "                    elif tags[i-1] == \"ADJ\" and tokens[i+1] not in self.times:\n",
    "                        trains.append(token)\n",
    "                    elif tokens[i-1] in self.train_adj_list:\n",
    "                        trains.append(token)\n",
    "                    elif tokens[i+1] in self.train_adj_list:\n",
    "                        trains.append(token)\n",
    "                    elif tokens[i+1] in self.train_noun_list:\n",
    "                        trains.append(token)          \n",
    "                    elif tags[i-1] in [\"CONJ\", \".\"]:\n",
    "                        if tokens[i-2] in self.is_number_train:\n",
    "                            trains.append(token) \n",
    "                    elif tags[i+1] in [\"CONJ\", \".\"]:\n",
    "                        if tokens[i+2] in self.is_number_train:\n",
    "                            trains.append(token) \n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "        return trains\n",
    "    \n",
    "    \n",
    "    def find_letter_trains(self):\n",
    "        \"\"\"This function finds letter trains and excludes instances of other possible meanings\n",
    "        including AC = air-conditioning, BC = because, E = east, W = west or with, F = fuck, \n",
    "        and S seems to have some weird results I think due to tokenization. \"\"\"\n",
    "        trains = []\n",
    "        tokens = self.tokens\n",
    "        tags = self.tags\n",
    "        for i,token in enumerate(tokens):\n",
    "            if token in self.is_letter_train:\n",
    "                if i or i<len(tokens)-1:\n",
    "                    \n",
    "                    \n",
    "                    if token == \"w\":\n",
    "                        \"\"\"disambiguates W trains from with and West street names\"\"\"\n",
    "                        if any(char.isdigit() for char in tokens[i+1]) == True:\n",
    "                            pass\n",
    "                            \"\"\"disambiguates W trains from with\"\"\"\n",
    "                        elif tags[i-1] in [\"ADJ\", \"DET\"]:\n",
    "                            trains.append(token)\n",
    "                        elif tokens[i+1] in self.train_noun_list:\n",
    "                            trains.append(token)\n",
    "                        elif tokens[i+1] in self.train_adj_list:\n",
    "                            trains.append(token)\n",
    "                        elif tokens[i-1] in self.train_adj_list:\n",
    "                            trains.append(token)\n",
    "                        else:\n",
    "                            pass    \n",
    "                    \n",
    "                    \n",
    "                    elif token == \"e\":\n",
    "                        \"\"\"disambiguates E and W trains from East and West street names\"\"\"\n",
    "                        if any(char.isdigit() for char in tokens[i+1]) == True:\n",
    "                            pass\n",
    "                        else:\n",
    "                            trains.append(token)\n",
    "                    \n",
    "                    \n",
    "                    elif token == \"ac\":\n",
    "                        \"\"\"disambiguates AC trains from air-conditioning\"\"\"\n",
    "                        if tokens[i+1] in [\"on\", \"off\", \"is\", \"blasting\"]:\n",
    "                            pass\n",
    "                        else:\n",
    "                            trains.append(token)\n",
    "                    \n",
    "                    \n",
    "                    elif token in [\"bc\", \"f\", \"s\",\"dm\"]:\n",
    "                        \"\"\"disambiguates BC trains from \"because\", F trains from \"fuck\" and S trains \n",
    "                        from tokenization (ie the s in \"it s\")\"\"\"\n",
    "                        if tags[i-1] in [\"ADJ\", \"DET\"] and tokens[i+1] !=\"ing\" and tokens[i-2] !=\"you\":\n",
    "                            trains.append(token)\n",
    "                        elif tokens[i+1] in self.train_noun_list:\n",
    "                            trains.append(token)\n",
    "                        elif tokens[i+1] in self.train_adj_list:\n",
    "                            trains.append(token)\n",
    "                        elif tokens[i-1] in self.train_adj_list:\n",
    "                            trains.append(token)\n",
    "                        else:\n",
    "                            pass\n",
    "                    else:\n",
    "                        trains.append(token)\n",
    "        return trains\n",
    "    \n",
    "\n",
    "    \n",
    "    def count_trains(self):\n",
    "        \"\"\"This function gathers the results of the previous 3 functions into one list\"\"\"\n",
    "        trains = self.find_a_trains()+self.find_letter_trains()+self.find_number_trains()\n",
    "        train_line_count = Counter(trains)\n",
    "        return train_line_count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2', 241),\n",
       " ('4', 203),\n",
       " ('3', 182),\n",
       " ('5', 168),\n",
       " ('6', 163),\n",
       " ('1', 150),\n",
       " ('q', 133),\n",
       " ('f', 133),\n",
       " ('a', 131),\n",
       " ('m', 129),\n",
       " ('n', 123),\n",
       " ('7', 108),\n",
       " ('d', 107),\n",
       " ('r', 107),\n",
       " ('j', 103),\n",
       " ('b', 84),\n",
       " ('c', 83),\n",
       " ('e', 75),\n",
       " ('l', 50),\n",
       " ('g', 30),\n",
       " ('ac', 22),\n",
       " ('w', 21),\n",
       " ('456', 21),\n",
       " ('mr', 11),\n",
       " ('25', 11),\n",
       " ('ef', 9),\n",
       " ('s', 6),\n",
       " ('45', 6),\n",
       " ('z', 5),\n",
       " ('dm', 4),\n",
       " ('bc', 3),\n",
       " ('nrw', 3),\n",
       " ('fg', 3),\n",
       " ('ace', 3),\n",
       " ('bdfm', 3),\n",
       " ('rw', 2),\n",
       " ('46', 2),\n",
       " ('nw', 1),\n",
       " ('nq', 1),\n",
       " ('ce', 1),\n",
       " ('jz', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_and_tags = Find_Trains(tokens,tags)\n",
    "tokens_and_tags.count_trains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
